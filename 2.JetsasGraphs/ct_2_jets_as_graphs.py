# -*- coding: utf-8 -*-
"""CT-2.Jets as graphs

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/ct-2-jets-as-graphs-360704fe-938b-41ae-a9c1-5793f6fba34c.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20240331/auto/storage/goog4_request%26X-Goog-Date%3D20240331T094839Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D01020b5cac4f171a09dcddc598c5d2104073708074e3197db55e8e522956f78ca5dc2038c417668116d25d7f1f5de3a7f4e70cbb6120129355fc3797e6f8dcc63267a3a63eca64837b2acab2560717df70556b0fa4b5fee81437eb8d83ebbeb57771d38ada691bc146dcc80627304f3f2f924d567435486759710f5c13790ade2df13db1575e7ad6f476b8adb1796dc14cb5c12f2673d961e49d97c03d90d1dc563c5173eb961882c68c3ef7edf4291324d9ba9ce943623f791a00ee239e756e6a708dc0fa29295dd5e1efc821f72f8dd767dd0991d9d245ac4c11db4926245d5fb73138183e5e69adfc70b1969c28a78e7e5d52f0c5e5c3402c65d4383c4117
"""

import torch
!pip uninstall torch-geometric torch-cluster  --y
!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html
!pip install git+https://github.com/pyg-team/pytorch_geometric.git

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install scikit-image
# import torch_cluster

"""## Taking only part of total images"""

!pip install gdown
import gdown
import gdown
import zipfile
import os
url = 'https://drive.google.com/uc?id=1WO2K-SfU2dntGU4Bb3IYBp9Rh7rtTYEr'
output_path = 'large_file.hdf5'
gdown.download(url, output_path, quiet=False)
import matplotlib.pyplot as plt
import numpy as np
import h5py
with h5py.File('large_file.hdf5', 'r') as file:
    train_imgs = np.array(file['X_jets'][:4096])
    test_imgs = np.array(file['X_jets'][4096:4096+1024])
    train_labels = np.array(file['y'][:4096])
    test_labels = np.array(file['y'][4096:4096+1024])
    print(train_imgs[0].shape)

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms.v2 as transforms
import os
import numpy as np
from PIL import Image
from torch_geometric.data import Data, DataLoader
from torch_geometric.nn import GraphConv, TopKPooling, global_mean_pool
from torch.nn import Linear, BatchNorm1d, ReLU
from torch_geometric.nn import knn_graph
import torch.nn.functional as F

class myData(torch.utils.data.Dataset):
    def __init__(self,imgs,labels):
        super().__init__()
        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize((16, 16))
            #transforms.Normalize([0.,0.,0.],[1.,1.,1.]),
        ])
        self.imgs = imgs
        self.labels = labels
    def __len__(self):
        return len(self.imgs)
    def __getitem__(self,idx):
        img = self.transform(self.imgs[idx])
        return img,torch.tensor(self.labels[idx]).to(torch.long)

train_loader = torch.utils.data.DataLoader(myData(train_imgs,train_labels), batch_size=64)
val_loader = torch.utils.data.DataLoader(myData(test_imgs,test_labels), batch_size=64)

for imgs,labels in train_loader:
    print(imgs.shape)
    img = imgs[0]
    plt.imshow(img.permute(1,2,0).cpu().numpy()[:,:,2])
    print(labels.shape)
    break

"""## GNN Model for Classification"""

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

from skimage.transform import resize

##resizing for efficient processing
train_imgs = [resize(img, (32, 32)) for img in train_imgs[:512*2]]
test_imgs = [resize(img, (32, 32)) for img in test_imgs[:128]]

# Helper function to convert image to point cloud
def image_to_point_cloud(image, label):
    height, width, c = image.shape
    points = []
    for y in range(height):
        for x in range(width):
            points.append([x, y, image[y, x][0],image[y, x][1],image[y, x][2]])  # (x, y, intensity)
    points = np.array(points)
    x = torch.tensor(points, dtype=torch.float)
    y = torch.tensor([label]).to(torch.long)
    edge_index = knn_graph(x, k=8, batch=None, loop=False, flow='source_to_target')##knn graph for edges from point cloud
    return Data(x=x, y=y, edge_index=edge_index)

# Load and preprocess data
train_data = []
test_data = []
for idx,img in enumerate(train_imgs[:512*2]):
    label = train_labels[idx]
    img = img
    data = image_to_point_cloud(img, label)
    train_data.append(data)

for idx,img in enumerate(test_imgs[:32]):
    label = test_labels[idx]
    img = img
    data = image_to_point_cloud(img, label)
    test_data.append(data)

# Create DataLoaders
train_loader = DataLoader(train_data, batch_size=32, shuffle=True)
test_loader = DataLoader(test_data, batch_size=32, shuffle=False)

# Define GNN model
class GNNModel(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels, num_classes):
        super(GNNModel, self).__init__()
        self.conv1 = GraphConv(in_channels, hidden_channels)
        self.conv2 = GraphConv(hidden_channels, hidden_channels)
        self.lin1 = Linear(hidden_channels, hidden_channels // 2)
        self.lin2 = Linear(hidden_channels // 2, num_classes)

    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = self.conv2(x, edge_index)
        x = global_mean_pool(x, batch)  # Use global mean pooling
        x = self.lin1(x)
        x = F.relu(x)
        x = self.lin2(x)
        return F.log_softmax(x, dim=-1)

# Initialize model, optimizer, and loss function
model = GNNModel(5, 64, num_classes=2).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
criterion = torch.nn.CrossEntropyLoss()

# Training loop
def train():
    model.train()
    for data in train_loader:
        data = data.to(device)
        optimizer.zero_grad()
        out = model(data)
        loss = criterion(out, data.y)
        loss.backward()
        optimizer.step()

# Test loop
def test():
    model.eval()
    correct = 0
    for data in test_loader:
        data = data.to(device)
        out = model(data)
        pred = out.max(dim=1)[1]
        correct += pred.eq(data.y).sum().item()
    return correct / len(test_loader.dataset)

accuracies = []
# Train and test model
for epoch in range(20):
    train()
    acc = test()
    accuracies.append(acc)
    print(f'Epoch: {epoch:03d}, Accuracy: {acc:.4f}')

plt.plot(accuracies)
plt.title("GNN Accuracy")
plt.xlabel("Epochs")
plt.show()

